{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61nFwaihsmyq"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "\n",
        "# Load MiDaS model\n",
        "midas_model = torch.hub.load(\"intel-isl/MiDaS\", \"DPT_Hybrid\")\n",
        "\n",
        "# Define device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "midas_model.to(device)\n",
        "midas_model.eval()\n",
        "\n",
        "def load_image(image_path):\n",
        "    \"\"\"Load an image from the specified path.\"\"\"\n",
        "    try:\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise FileNotFoundError(f\"Image not found at {image_path}\")\n",
        "        return image\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading image: {e}\")\n",
        "        return None\n",
        "\n",
        "def preprocess_image(image):\n",
        "    \"\"\"Preprocess the image to fit the requirements of MiDaS model.\"\"\"\n",
        "    # Convert to RGB\n",
        "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    # Resize to fit model input size\n",
        "    image_resized = cv2.resize(image_rgb, (384, 384))\n",
        "    # Normalize the image\n",
        "    image_normalized = image_resized / 255.0  # Normalize pixel values to [0, 1]\n",
        "    # Convert to tensor and add batch dimension\n",
        "    image_tensor = torch.tensor(image_normalized, dtype=torch.float32).permute(2, 0, 1).unsqueeze(0)\n",
        "    return image_tensor\n",
        "\n",
        "def predict_depth(image_tensor):\n",
        "    \"\"\"Predict depth map.\"\"\"\n",
        "    # Predict depth map\n",
        "    with torch.no_grad():\n",
        "        prediction = midas_model(image_tensor.to(device))\n",
        "    depth_map = prediction.squeeze().cpu().numpy()\n",
        "    return depth_map\n",
        "\n",
        "def detect_edges(image):\n",
        "    \"\"\"Detect edges using the Canny edge detection algorithm.\"\"\"\n",
        "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray_image, 50, 150)\n",
        "    return edges\n",
        "\n",
        "def find_contours(image):\n",
        "    \"\"\"Find contours in the image.\"\"\"\n",
        "    contours, _ = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    return contours\n",
        "\n",
        "def draw_contours(image, contours):\n",
        "    \"\"\"Draw contours on the image.\"\"\"\n",
        "    contour_image = image.copy()\n",
        "    cv2.drawContours(contour_image, contours, -1, (0, 255, 0), 2)\n",
        "    return contour_image\n",
        "\n",
        "def extract_floor_plan(edges):\n",
        "    \"\"\"Extract floor plan from edge-detected image.\"\"\"\n",
        "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    floor_plan = np.zeros_like(edges)\n",
        "    cv2.drawContours(floor_plan, contours, -1, (255), thickness=cv2.FILLED)\n",
        "    return floor_plan\n",
        "\n",
        "def display_images(images, titles):\n",
        "    \"\"\"Display multiple images side by side.\"\"\"\n",
        "    plt.figure(figsize=(15, 5))\n",
        "    for i in range(len(images)):\n",
        "        plt.subplot(1, len(images), i + 1)\n",
        "        if len(images[i].shape) == 2:\n",
        "            plt.imshow(images[i], cmap='gray')\n",
        "        else:\n",
        "            plt.imshow(images[i])\n",
        "        plt.title(titles[i])\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "def process_image(image_path):\n",
        "    \"\"\"Process the image to predict depth map and extract floor plan.\"\"\"\n",
        "    # Load the image\n",
        "    image = load_image(image_path)\n",
        "    if image is None:\n",
        "        return\n",
        "\n",
        "    # Preprocess the image for MiDaS model\n",
        "    image_tensor = preprocess_image(image)\n",
        "\n",
        "    # Predict depth map\n",
        "    depth_map = predict_depth(image_tensor)\n",
        "\n",
        "    # Detect edges\n",
        "    edges = detect_edges(image)\n",
        "\n",
        "    # Find contours\n",
        "    contours = find_contours(edges)\n",
        "\n",
        "    # Draw contours on the original image\n",
        "    contour_image = draw_contours(image, contours)\n",
        "\n",
        "    # Extract floor plan from edges\n",
        "    floor_plan = extract_floor_plan(edges)\n",
        "\n",
        "    # Display results\n",
        "    display_images([image, contour_image, depth_map, floor_plan],\n",
        "                   ['Original Image', 'Contours', 'Depth Map', 'Extracted Floor Plan'])\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Provide the path to the image\n",
        "    image_path = ''  # Change this to the path of your image\n",
        "\n",
        "    # Process the image\n",
        "    process_image(image_path)\n"
      ]
    }
  ]
}